{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch\n",
    "\n",
    "Next I'll show you how to build a neural network with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things like usual\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)    \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)           #this will load the data in batch of 64\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53f03eb6a0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 to build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.9474e-02,  2.9189e-02, -3.1905e-02,  ..., -7.8261e-03,\n",
      "          5.1401e-03, -1.0354e-02],\n",
      "        [ 2.7496e-03,  1.0032e-02,  3.2259e-02,  ...,  3.0156e-02,\n",
      "         -3.1928e-02,  5.2612e-03],\n",
      "        [-1.6033e-02, -2.8301e-02,  5.2020e-03,  ...,  2.7693e-02,\n",
      "         -1.8267e-02, -2.1681e-02],\n",
      "        ...,\n",
      "        [-1.4371e-02,  2.1134e-02, -9.9003e-03,  ...,  2.8475e-02,\n",
      "         -1.1272e-02, -2.1671e-02],\n",
      "        [-1.3488e-02,  1.3957e-02,  1.3979e-02,  ..., -2.9007e-02,\n",
      "          1.2767e-03, -1.1127e-02],\n",
      "        [-2.4882e-02, -9.3831e-04,  2.2256e-02,  ..., -2.7963e-02,\n",
      "          3.4100e-02, -5.5810e-03]])\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-0.5404, -1.7841,  1.1915, -0.3353,  2.9657, -3.2016, -0.0793,\n",
      "         3.1496, -0.5419, -1.8447, -0.2701,  2.4988,  0.1154,  2.9625,\n",
      "         0.3288,  2.2522, -1.1653, -2.3477, -2.7679, -1.1899,  1.4205,\n",
      "         0.3568, -1.2603,  0.7458,  1.8009,  0.1706, -2.3979,  1.6267,\n",
      "         2.7529,  2.2081,  1.3291, -0.2250,  2.3621, -1.6053,  1.4694,\n",
      "        -3.3368,  0.9221,  1.1727,  3.1408, -3.3318,  2.9344, -1.7737,\n",
      "         3.2124, -2.2991, -2.9555,  2.4101,  1.4180, -1.7950,  2.1095,\n",
      "         3.1048, -1.5843, -3.3458,  2.6670,  0.0186, -1.3377, -2.8727,\n",
      "        -2.5884,  0.0040,  2.0553,  0.9038,  0.8550,  3.3771,  1.5449,\n",
      "        -2.7154,  2.4650,  0.6703, -2.6266,  2.0998, -0.8536, -1.2714,\n",
      "        -2.5582,  1.1369,  0.5160,  1.4807,  3.3948,  0.3553, -0.1606,\n",
      "        -1.1776,  2.4702,  1.8497,  0.5020,  1.8816, -0.4121, -0.9193,\n",
      "         3.0516, -0.2059,  1.1941,  0.1462, -1.3523, -3.1588,  2.0142,\n",
      "         3.3173,  0.1846, -1.6702,  1.7491,  3.1220,  3.0000,  3.3674,\n",
      "         2.6249,  1.1374, -2.8412, -2.1025, -3.1908,  2.2501,  3.4916,\n",
      "        -1.8953, -0.3531,  1.3049, -0.6838, -3.4680,  0.9605,  1.8347,\n",
      "        -3.2551,  1.3384,  0.8173, -3.0015,  0.1064,  1.1557,  1.5829,\n",
      "         0.5455,  1.8150, -2.6019, -1.9924, -0.0020, -0.1321, -1.5516,\n",
      "        -3.0426, -1.0701])\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8829e-03, -2.7460e-02,  4.8189e-03,  ..., -5.9674e-03,\n",
       "         -8.2085e-03,  4.6240e-03],\n",
       "        [ 2.0512e-03, -7.4505e-03,  2.0405e-02,  ..., -5.5904e-03,\n",
       "          1.1482e-02,  7.6615e-03],\n",
       "        [-2.8591e-03,  1.9580e-02,  1.3204e-03,  ...,  1.2997e-02,\n",
       "          9.5853e-03,  3.7160e-03],\n",
       "        ...,\n",
       "        [ 2.8606e-03, -3.5992e-04,  2.2113e-03,  ...,  9.0634e-04,\n",
       "         -1.4285e-02,  1.2764e-03],\n",
       "        [ 1.4248e-02, -1.5072e-02,  3.3902e-04,  ...,  2.3186e-03,\n",
       "          5.3048e-03,  2.3269e-03],\n",
       "        [ 1.5932e-02,  2.1060e-03,  6.9409e-03,  ...,  1.0187e-02,\n",
       "         -4.5758e-03,  1.3091e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 to build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 to build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Next notebook we will learn how to train our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
